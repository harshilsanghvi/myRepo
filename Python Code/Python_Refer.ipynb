{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def readdata(path):\n",
    "    return data = pd.read_csv(path,sep=r'\\s*,\\s*',engine='python',na_values=\"?\")\n",
    "def dataanalysis(data):\n",
    "    print data.tail()\n",
    "    print data.head()\n",
    "    print data.dtypes#structure of the columns\n",
    "def descstats(data):\n",
    "    print data.describe()\n",
    "    print data.std()\n",
    "    print data.quantile([.25,.5,.75])\n",
    "    print data.var()\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In Windows run pip commands\n",
    "C:\\Users\\HS> C:\\Python27\\Scripts\\pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------SUMMARY--------------\n",
    "# data.dtypes\n",
    "# data.head(1)\n",
    "# data.tail(3)\n",
    "# data.describe().unstack()\n",
    "# data['Age'].mean()\n",
    "# data['Age'].median()\n",
    "# data['Age'].mode()\n",
    "# data['Age'].apply(gmean, axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#---------COLUMNS---------------\n",
    "# data[\"Age\"].iloc[-4:]\n",
    "# data[\"Age\"].head()\n",
    "# data[\"Age\"].tolist()\n",
    "# print(np.array(data['Hours_per_week']))\n",
    "# data.Age.head(2)\n",
    "# df = data.set_index('Age') OR data.set_index('Age'),inplace = True)\n",
    "# data[[\"Age\",\"Education\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ------------------------------------PREPROCESSING-----------------------------------------------------\n",
    "\n",
    "# # Normalize\n",
    "# X = np.array(data[\"Age\"].values)#.tolist())\n",
    "# X = preprocessing.normalize(X)\n",
    "# # Scaling/Standardize\n",
    "# X = preprocessing.normalize(X)\n",
    "#----------ROW MANIPULATION-------------\n",
    "# rows = [data[\"Age\"].index(x) if x is None else \"Value\" for x in data[\"Age\"]]\n",
    "# [i for i, x in enumerate(rows) if x != \"Value\"]\n",
    "\n",
    "\n",
    "# ---------MISSING VALUES---------------\n",
    "# 1. Ignore missing values 2. Remove missing values 3. Fill with related values 4. Fill with static values\n",
    "# 2.\n",
    "# data[[\"Age\",\"Hour\"]].dropna()\n",
    "# data[[\"Age\",\"Hour\"]].dropna(how = \"all\",inplace=True)\n",
    "# 3. \n",
    "# data[[\"Age\"]].fillna(method=\"ffill\")\n",
    "# 4.\n",
    "# method = \"bfill\" OR value = -9999\n",
    "# data.isnull().values.sum() ----- To count no. of rows with null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normilization\n",
    "Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n",
    "It is useful to scale the input attributes for a model that relies on the magnitude of values, such as distance measures used in k-nearest neighbors and in the preparation of coefficients in regression.\n",
    "\n",
    "### Standardization\n",
    "Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).\n",
    "It is useful to standardize attributes for a model that relies on the distribution of attributes such as Gaussian processes.\n",
    "\n",
    "- It is hard to know whether rescaling your data will improve the performance of your algorithms before you apply them. If often can, but not always.\n",
    "A good tip is to create rescaled copies of your dataset and race them against each other using your test harness and a handful of algorithms you want to spot check. This can quickly highlight the benefits (or lack there of) of rescaling your data with given models, and which rescaling method may be worthy of further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------- MATPLOTLIB PLOTS------------\n",
    "\n",
    "# QQPlot\n",
    "stats.probplot(data[\"Age\"], dist=\"norm\", plot=pylab)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QQPlot \n",
    "\n",
    "\n",
    "Plots in matplotlib\n",
    "\n",
    "line plot\n",
    "bo - b is blue and o means dot\n",
    "k - line plot\n",
    "bs - blue square\n",
    "g^ - green triangle \n",
    "-- dashed line plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "http://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "\n",
    "--labelencoder - Encode labels with value between 0 and n_classes-1.\n",
    "LabelEncoder can be used to normalize labels.It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.\n",
    "\n",
    "--why do we convert categorical class labels to integers for classification?\n",
    "Scikit learn only handles real numbers I believe. So you need to do something like one hot encoding where n numerical dimensions are used to represent membership in the categories. If you just pass in strings they'll get cast to floats in unpredictable ways."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
