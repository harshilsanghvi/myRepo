{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def readdata(path):\n",
    "    return data = pd.read_csv(path,sep=r'\\s*,\\s*',engine='python',na_values=\"?\")\n",
    "def dataanalysis(data):\n",
    "    print data.tail()\n",
    "    print data.head()\n",
    "    print data.dtypes#structure of the columns\n",
    "def descstats(data):\n",
    "    print data.describe()\n",
    "    print data.std()\n",
    "    print data.quantile([.25,.5,.75])\n",
    "    print data.var()\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In Windows run pip commands\n",
    "C:\\Users\\HS> C:\\Python27\\Scripts\\pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------SUMMARY--------------\n",
    "# data.dtypes\n",
    "# data.head(1)\n",
    "# data.tail(3)\n",
    "# data.describe().unstack()\n",
    "# data['Age'].mean()\n",
    "# data['Age'].median()\n",
    "# data['Age'].mode()\n",
    "# data['Age'].apply(gmean, axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------ROWS-------------------\n",
    "# df.loc[df['column_name'] == some_value]\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#---------COLUMNS---------------\n",
    "# data[\"Age\"].iloc[-4:]\n",
    "# data[\"Age\"].head()\n",
    "# data[\"Age\"].tolist()\n",
    "# print(np.array(data['Hours_per_week']))\n",
    "# data.Age.head(2)\n",
    "# df = data.set_index('Age') OR data.set_index('Age'),inplace = True)\n",
    "# data[[\"Age\",\"Education\"]]\n",
    "# len(data.columns) - count no. of columns\n",
    "# data[\"Country\"].value_counts() - will count no. of occurences of factors in column\n",
    "# lis = data.select_dtypes(include=['int64']) - get all columns of int64 type\n",
    "\n",
    "# data['Target'] = [1 if x == '<=50K' else 0 for x in data['Target']] - for class variable replace string with 0 and 1\n",
    "# data['Occupation'].replace(1, 'Male',inplace=True)\n",
    "# analyse = pd.crosstab(index=data[\"Occupation\"],columns=\"count\")  # Make a crosstab , to count the classes in the \n",
    "# categorical /class variable\n",
    "# df.ix[:, df.columns != 'b'] - select all columns except 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inplace = true - means update the original string and not create a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -----------CORRELATION------------------\n",
    "\n",
    "#  1 way\n",
    "# PEARSON \n",
    "# http://stackoverflow.com/questions/33997753/calculating-pairwise-correlation-among-all-columns\n",
    "# import itertools\n",
    "# lis = data.select_dtypes(include=['int64'])\n",
    "# correlations = {}\n",
    "# columns = lis.columns.tolist()\n",
    "# for col_a, col_b in itertools.combinations(columns, 2):\n",
    "#     correlations[col_a + '__' + col_b] = pearsonr(lis.loc[:, col_a], lis.loc[:, col_b])\n",
    "# # print correlations\n",
    "# result = pd.DataFrame.from_dict(correlations, orient='index')\n",
    "# result.columns = ['PCC', 'p-value']\n",
    "# print(result.sort_index())\n",
    "\n",
    "#  2 way pearson for numerical, spearman for categorical\n",
    "# sns.heatmap(data.corr(method = 'pearson/spearman/kindall'), square=True)\n",
    "# plt.show()\n",
    "\n",
    "# LABEL ENCODER AND HEAT MAP\n",
    "# from sklearn import preprocessing\n",
    "# # Encode the categorical features as numbers\n",
    "# def number_encode_features(df):\n",
    "#     result = df.copy()\n",
    "#     encoders = {}\n",
    "# #     df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "#     for column in result.columns:\n",
    "#         if result.dtypes[column] == np.object:\n",
    "#             encoders[column] = preprocessing.LabelEncoder()\n",
    "#             result[column] = encoders[column].fit_transform(result[column])\n",
    "#     return result, encoders\n",
    "# encoded_data, _ = number_encode_features(data)\n",
    "# sns.heatmap(encoded_data.corr(), square=True)\n",
    "# plt.show()\n",
    "# # Label encoder function in scikit-learn package is used  \n",
    "\n",
    "# Calculate the correlation and plot it\n",
    "# ONE HOT ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Connectors -\n",
    "1. r/python to tableau\n",
    "2. mongo r/python\n",
    "3. mongo to hdfs/spark, hdfs/spark to mongo \n",
    "4. Shinny app\n",
    "5. sql/twitter to Nosql \n",
    "6. spark to hive to sql.\n",
    "\n",
    "# # ------------------------------------PREPROCESSING-----------------------------------------------------\n",
    "\n",
    "# # Normalize\n",
    "# X = np.array(data[\"Age\"].values)#.tolist())\n",
    "# X = preprocessing.normalize(X)\n",
    "# # Scaling/Standardize\n",
    "# X = preprocessing.normalize(X)\n",
    "#----------ROW MANIPULATION-------------\n",
    "# rows = [data[\"Age\"].index(x) if x is None else \"Value\" for x in data[\"Age\"]]\n",
    "# [i for i, x in enumerate(rows) if x != \"Value\"]\n",
    "\n",
    "\n",
    "# ---------MISSING VALUES---------------\n",
    "# 1. Ignore missing values 2. Remove missing values 3. Fill with related values 4. Fill with static values\n",
    "# 2.\n",
    "# data[[\"Age\",\"Hour\"]].dropna()\n",
    "# data[[\"Age\",\"Hour\"]].dropna(how = \"all\",inplace=True)\n",
    "# 3. \n",
    "# data[[\"Age\"]].fillna(method=\"ffill\")\n",
    "# 4.\n",
    "# method = \"bfill\" OR value = -9999\n",
    "# data.isnull().values.sum() ----- To count no. of rows with null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normilization\n",
    "Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n",
    "It is useful to scale the input attributes for a model that relies on the magnitude of values, such as distance measures used in k-nearest neighbors and in the preparation of coefficients in regression.\n",
    "\n",
    "### Standardization\n",
    "Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).\n",
    "It is useful to standardize attributes for a model that relies on the distribution of attributes such as Gaussian processes.\n",
    "\n",
    "- It is hard to know whether rescaling your data will improve the performance of your algorithms before you apply them. If often can, but not always.\n",
    "A good tip is to create rescaled copies of your dataset and race them against each other using your test harness and a handful of algorithms you want to spot check. This can quickly highlight the benefits (or lack there of) of rescaling your data with given models, and which rescaling method may be worthy of further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normilization\n",
    "Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n",
    "It is useful to scale the input attributes for a model that relies on the magnitude of values, such as distance measures used in k-nearest neighbors and in the preparation of coefficients in regression.\n",
    "\n",
    "### Standardization\n",
    "Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).\n",
    "It is useful to standardize attributes for a model that relies on the distribution of attributes such as Gaussian processes.\n",
    "\n",
    "- It is hard to know whether rescaling your data will improve the performance of your algorithms before you apply them. If often can, but not always.\n",
    "A good tip is to create rescaled copies of your dataset and race them against each other using your test harness and a handful of algorithms you want to spot check. This can quickly highlight the benefits (or lack there of) of rescaling your data with given models, and which rescaling method may be worthy of further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------- MATPLOTLIB PLOTS------------\n",
    "\n",
    "# QQPlot\n",
    "stats.probplot(data[\"Age\"], dist=\"norm\", plot=pylab)\n",
    "# BOX PLOT\n",
    "import math as m \n",
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 3\n",
    "rows = m.ceil(float(data.shape[1]) / cols)\n",
    "j = 0 \n",
    "for i, column in enumerate(data.columns):\n",
    "    if data.dtypes[column] != np.object:\n",
    "        j += 1\n",
    "        ax = fig.add_subplot(2, cols, j)\n",
    "        ax.set_title(column)\n",
    "        plt.boxplot(data[column])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "# ------------SNS PLOTS-----------------------\n",
    "sns.boxplot(x = data['Target'],y = data[column])\n",
    "\n",
    "\n",
    "# HISTOGRAM\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "##--- SUBPOT(3,4,i) -- Subplot syntax , row, column , plot number\n",
    "ax = fig.add_subplot(2, cols, j)\n",
    "data[column].hist(axes=ax)\n",
    "        \n",
    "# ------------SNS - SCATTER PLOT--------------------\n",
    "sns.regplot(data['Age'],data['fnlwgt'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "QQPlot \n",
    "\n",
    "\n",
    "Plots in matplotlib\n",
    "\n",
    "line plot\n",
    "bo - b is blue and o means dot\n",
    "k - line plot\n",
    "bs - blue square\n",
    "g^ - green triangle \n",
    "-- dashed line plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "http://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "\n",
    "--labelencoder - Encode labels with value between 0 and n_classes-1.\n",
    "LabelEncoder can be used to normalize labels.It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.\n",
    "\n",
    "--why do we convert categorical class labels to integers for classification?\n",
    "Scikit learn only handles real numbers I believe. So you need to do something like one hot encoding where n numerical dimensions are used to represent membership in the categories. If you just pass in strings they'll get cast to floats in unpredictable ways."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
