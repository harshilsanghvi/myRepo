{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "import sklearn as skl\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.cross_validation as cross_validation\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.tree as tree\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.stats import trim_mean, kurtosis, spearmanr, kendalltau, pearsonr\n",
    "from scipy.stats.mstats import mode, gmean, hmean\n",
    "import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/harshil/BDAP/Python Code/adultdata.csv\", names = [\"Age\", \"Workclass\", \"fnlwgt\", \n",
    "        \"Education\", \"Education-Num\", \"Martial_Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\",\n",
    "        \"Capital_Gain\", \"Capital_Loss\",\"Hour\", \"Country\", \"Target\"],\n",
    "        sep=r'\\s*,\\s*',engine='python',na_values=\"?\")\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Target']\n",
    "data['Target'] = [1 if x == '<=50K' else 0 for x in data['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyse = pd.crosstab(index=data[\"Occupation\"],columns=\"count\")  # Make a crosstab                       \n",
    "# data['Occupation'].replace(1, 'Male',inplace=True)\n",
    "data['Occupation'].replace(['Armed-Forces','Craft-repair','Exec-managerial',\n",
    "                            'Farming-fishing','Handlers-cleaners','Machine-op-inspct',\n",
    "                            'Transport-moving'],['Military','Blue-Collar','White-Collar','Blue-Collar','Blue-Collar','Blue-Collar',\n",
    "                           'Blue-Collar'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyse = pd.crosstab(index=data[\"Occupation\"],columns=\"count\")  # Make a crosstab                       \n",
    "analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------5 number summary----------------------\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------MEASURES OF VARIABILITY---------------\n",
    "print data.std()\n",
    "print data.quantile([.25,.5,.75])\n",
    "print data.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-----------QQ PLOTS------------------------------\n",
    "import scipy.stats as stats\n",
    "import pylab\n",
    "stats.probplot(data[\"Age\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(321)\n",
    "stats.probplot(data[\"fnlwgt\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(322)\n",
    "stats.probplot(data[\"Education-Num\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(323)\n",
    "stats.probplot(data[\"Capital_Gain\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(324)\n",
    "stats.probplot(data[\"Capital_Loss\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(325)\n",
    "stats.probplot(data[\"Hour\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(326)\n",
    "\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------BOX PLOT-----------------------------\n",
    "# import plotly.graph_objs as go\n",
    "import math as m \n",
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 3\n",
    "rows = m.ceil(float(data.shape[1]) / cols)\n",
    "j = 0 \n",
    "for i, column in enumerate(data.columns):\n",
    "    if data.dtypes[column] != np.object:\n",
    "        j += 1\n",
    "        ax = fig.add_subplot(2, cols, j)\n",
    "        ax.set_title(column)\n",
    "        sns.boxplot(x = data['Target'],y = data[column])\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#------------HISTOGRAM-----------------------------\n",
    "# Analyse Data\n",
    "\n",
    "import math as m \n",
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 5\n",
    "rows = m.ceil(float(data.shape[1]) / cols)\n",
    "for i, column in enumerate(data.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    if data.dtypes[column] == np.object:\n",
    "        data[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "    else:\n",
    "        data[column].hist(axes=ax)\n",
    "        plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------SCATTER PLOT-------------------------\n",
    "\n",
    "pylab.subplot(331)\n",
    "sns.regplot(data['Age'],data['fnlwgt'])\n",
    "pylab.subplot(332)\n",
    "sns.regplot(data['Age'],data['Education-Num'])\n",
    "pylab.subplot(333)\n",
    "sns.regplot(data['Age'],data['Capital_Gain'])\n",
    "pylab.subplot(334)\n",
    "sns.regplot(data['Age'],data['Capital_Loss'])\n",
    "pylab.subplot(335)\n",
    "sns.regplot(data['Age'],data['Hour'])\n",
    "pylab.subplot(336)\n",
    "sns.regplot(data['Education-Num'],data['fnlwgt'])\n",
    "pylab.subplot(337)\n",
    "sns.regplot(data['Education-Num'],data['Capital_Gain'])\n",
    "pylab.subplot(338)\n",
    "sns.regplot(data['Education-Num'],data['Capital_Loss'])\n",
    "pylab.subplot(339)\n",
    "sns.regplot(data['Education-Num'],data['Hour'])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "plt.show()\n",
    "\n",
    "# data['Target'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(data[\"Country\"].value_counts() / data.shape[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBSERVATIONS\n",
    "1. Most of the data is concentrated around US\n",
    "\n",
    "### Correlation\n",
    "\n",
    "1. Need to convert categorical variable into numerical variables. Using Label Encoder \n",
    "2. Remove correlated variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Encode the categorical features as numbers\n",
    "def number_encode_features(df):\n",
    "    result = df.copy()\n",
    "    encoders = {}\n",
    "#     df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "    for column in result.columns:\n",
    "        if result.dtypes[column] == np.object:\n",
    "            encoders[column] = preprocessing.LabelEncoder()\n",
    "            result[column] = encoders[column].fit_transform(result[column])\n",
    "    return result, encoders\n",
    "    \n",
    "# Calculate the correlation and plot it\n",
    "encoded_data, _ = number_encode_features(data)\n",
    "sns.heatmap(encoded_data.corr(), square=True)\n",
    "plt.show()\n",
    "# Label encoder function in scikit-learn package is used  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[[\"Education\", \"Education-Num\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We Remove Education column as Education and Education-Num are highly correlated.\n",
    "- Now to model the data, we encode the categorical variable and create histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_data, encoders = number_encode_features(data)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 5\n",
    "rows = m.ceil(float(encoded_data.shape[1]) / cols)\n",
    "for i, column in enumerate(encoded_data.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    encoded_data[column].hist(axes=ax)\n",
    "    plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before modelling, we divide the data into train and test sets. We scale all the data with mean 0 and variance 1 using StandardScalar in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(encoded_data[encoded_data.columns - [\"Target\"]], encoded_data[\"Target\"], train_size=0.70)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train.astype('float64')), columns=X_train.columns)\n",
    "X_test = scaler.transform(X_test.astype(\"float64\"))\n",
    "# ?X_train.astype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls = linear_model.LogisticRegression()\n",
    "\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=encoders[\"Target\"].classes_, yticklabels=encoders[\"Target\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "print \"F1 score: %f\" % skl.metrics.f1_score(y_test, y_pred)\n",
    "coefs = pd.Series(cls.coef_[0], index=X_train.columns)\n",
    "coefs.sort()\n",
    "plt.subplot(2,1,2)\n",
    "coefs.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Label encoding, the marital status values are ranging from 0 to 6 and the order is important. In practice there\n",
    "is no particular order in that feature. We can fix the issue using binary features by inrtoducing dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_data = pd.get_dummies(data)\n",
    "# Let's fix the Target as it will be converted to dummy vars too\n",
    "binary_data[\"Target\"] = binary_data[\"Target_>50K\"]\n",
    "del binary_data[\"Target_<=50K\"]\n",
    "del binary_data[\"Target_>50K\"]\n",
    "plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(binary_data.corr(), square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(binary_data[binary_data.columns - [\"Target\"]], binary_data[\"Target\"], train_size=0.70)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls = linear_model.LogisticRegression()\n",
    "\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=encoders[\"Target\"].classes_, yticklabels=encoders[\"Target\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "print \"F1 score: %f\" % skl.metrics.f1_score(y_test, y_pred)\n",
    "coefs = pd.Series(cls.coef_[0], index=X_train.columns)\n",
    "coefs.sort_values(inplace=True)\n",
    "ax = plt.subplot(2,1,2)\n",
    "coefs.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries: dataframe manipulation, machine learning, os tools\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    " # Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# change working directory to where the dataset is\n",
    "# os.chdir(\"C:/Users/JD87417/Desktop/python work/Coursera\")\n",
    "\n",
    "# Load the dataset (http://archive.ics.uci.edu/ml/datasets/Adult)\n",
    "AH_data = pd.read_csv(\"/media/harshil/Harshil/Ubuntu/prepdata.csv\")\n",
    "# AH_data = AH_data.drop('(Intercept)',axis=1)\n",
    "data_clean = AH_data.dropna()\n",
    "\n",
    "# encode categorical features\n",
    "# done in R (C:\\Users\\JD87417\\Desktop\\python work\\Coursera\\python_adult2_clean.R)\n",
    "# do one hot encoding and name the columns\n",
    "\n",
    "# summary statistics including counts, mean, stdev, quartiles\n",
    "data_clean.head(n=1)\n",
    "# data_clean.dtypes # data types of each variable\n",
    "# data_clean.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_clean[\"Education_num\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split into training and testing sets\n",
    "# Specifying predictor x variables\n",
    "\n",
    "predictors = data_clean[[\"age\", \"workclassLocal-gov\", \"workclassPrivate\",\n",
    "\"workclassSelf-emp-inc\", \"workclassSelf-emp-not-inc\", \"workclassState-gov\",\n",
    "\"workclassWithout-pay\", \"fnlwgt\", \"education11th\", \"education12th\",\n",
    "\"education1st-4th\", \"education5th-6th\", \"education7th-8th\", \"education9th\",\n",
    "\"educationAssoc-acdm\", \"educationAssoc-voc\", \"educationBachelors\",\n",
    "\"educationDoctorate\", \"educationHS-grad\", \"educationMasters\",\n",
    "\"educationPreschool\", \"educationProf-school\", \"educationSome-college\",\n",
    "\"Education_num\", \"martial_statusMarried-AF-spouse\", \"martial_statusMarried-civ-spouse\",\n",
    "\"martial_statusMarried-spouse-absent\", \"martial_statusNever-married\",\n",
    "\"martial_statusSeparated\", \"martial_statusWidowed\", \"occupationArmed-Forces\",\n",
    "\"occupationCraft-repair\", \"occupationExec-managerial\", \"occupationFarming-fishing\",\n",
    "\"occupationHandlers-cleaners\", \"occupationMachine-op-inspct\",\n",
    "\"occupationOther-service\", \"occupationPriv-house-serv\", \"occupationProf-specialty\",\n",
    "\"occupationProtective-serv\", \"occupationSales\", \"occupationTech-support\",\n",
    "\"occupationTransport-moving\", \"relationshipNot-in-family\", \"relationshipOther-relative\",\n",
    "\"relationshipOwn-child\", \"relationshipUnmarried\", \"relationshipWife\",\n",
    "\"raceAsian-Pac-Islander\", \"raceBlack\", \"raceOther\", \"raceWhite\",\n",
    "\"sexMale\", \"capital_gain\", \"capital_loss\", \"hours_per_week\",\n",
    "\"native_countryCanada\", \"native_countryChina\", \"native_countryColumbia\",\n",
    "\"native_countryCuba\", \"native_countryDominican-Republic\", \"native_countryEcuador\",\n",
    "\"native_countryEl-Salvador\", \"native_countryEngland\", \"native_countryFrance\",\n",
    "\"native_countryGermany\", \"native_countryGreece\", \"native_countryGuatemala\",\n",
    "\"native_countryHaiti\", \"native_countryHoland-Netherlands\", \"native_countryHonduras\",\n",
    "\"native_countryHong\", \"native_countryHungary\", \"native_countryIndia\",\n",
    "\"native_countryIran\", \"native_countryIreland\", \"native_countryItaly\",\n",
    "\"native_countryJamaica\", \"native_countryJapan\", \"native_countryLaos\",\n",
    "\"native_countryMexico\", \"native_countryNicaragua\", \"native_countryOutlying-US(Guam-USVI-etc)\",\n",
    "\"native_countryPeru\", \"native_countryPhilippines\", \"native_countryPoland\",\n",
    "\"native_countryPortugal\", \"native_countryPuerto-Rico\", \"native_countryScotland\",\n",
    "\"native_countrySouth\", \"native_countryTaiwan\", \"native_countryThailand\",\n",
    "\"native_countryUnited-States\",\n",
    "\"native_countryVietnam\", \"native_countryYugoslavia\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y repsonse variable\n",
    "targets = data_clean\n",
    "\n",
    "# concurrent split of x's, y, at 40%\n",
    "pred_train, pred_test, tar_train, tar_test  = train_test_split(predictors, targets, test_size=.4)\n",
    "\n",
    "# shape/dimensions of the DataFrame\n",
    "print pred_train.shape\n",
    "print pred_test.shape\n",
    "print tar_train.shape\n",
    "print tar_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build model on training data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators is the amount of trees to build\n",
    "classifier=RandomForestClassifier(n_estimators=25)\n",
    "# fit the RandomForest Model\n",
    "classifier=classifier.fit(pred_train,tar_train)\n",
    "# prediction scoring of the model (array of binary 0-1)\n",
    "predictions=classifier.predict(pred_test)\n",
    "# confusion matrix / missclassification matrix\n",
    "sklearn.metrics.confusion_matrix(tar_test,predictions)\n",
    "sklearn.metrics.accuracy_score(tar_test, predictions)\n",
    "\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(pred_train,tar_train)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(max(model.feature_importances_))\n",
    "max_val = np.where(model.feature_importances_ == max(model.feature_importances_))\n",
    "\n",
    "min_val = np.where(model.feature_importances_ == min(model.feature_importances_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(max_val, min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running a different number of trees and see the effect\n",
    " of that on the accuracy of the prediction\n",
    "\"\"\"\n",
    "\n",
    "trees=range(25)\n",
    "accuracy=np.zeros(25)\n",
    "\n",
    "for idx in range(len(trees)):\n",
    "    classifier=RandomForestClassifier(n_estimators=idx + 1)\n",
    "    classifier=classifier.fit(pred_train,tar_train)\n",
    "    predictions=classifier.predict(pred_test)\n",
    "    accuracy[idx]=sklearn.metrics.accuracy_score(tar_test, predictions)\n",
    "\n",
    "plt.cla()\n",
    "plt.plot(trees, accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train = pd.read_csv(\"/home/harshil/BDAP/Python Code/adultdata.csv\", names = [\"Age\", \"Workclass\", \"fnlwgt\", \n",
    "        \"Education\", \"Education-Num\", \"Martial_Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\",\n",
    "        \"Capital_Gain\", \"Capital_Loss\",\"Hour\", \"Country\", \"Target\"],\n",
    "        sep=r'\\s*,\\s*',engine='python',na_values=\"?\")\n",
    "data = data.dropna()\n",
    "# train = pd.read_csv('train_modified.csv')\n",
    "target = 'income_target>50K'\n",
    "IDcol = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['income_target>50K'])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain['income_target>50K'], cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['income_target>50K'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['income_target>50K'], dtrain_predprob)\n",
    "    \n",
    "    if performCV:\n",
    "        print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in data_clean.columns if x not in [target]]\n",
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "modelfit(gbm0, data_clean, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "data = pd.read_csv(\"/home/harshil/BDAP/Python Code/adultdata.csv\", names = [\"Age\", \"Workclass\", \"fnlwgt\", \n",
    "        \"Education\", \"Education-Num\", \"Martial_Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\",\n",
    "        \"Capital_Gain\", \"Capital_Loss\",\"Hour\", \"Country\", \"Target\"],\n",
    "        sep=r'\\s*,\\s*',engine='python',na_values=\"?\")\n",
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Target']\n",
    "data['Target'] = [1 if x == '<=50K' else 0 for x in data['Target']]\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Martial_Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital_Gain</th>\n",
       "      <th>Capital_Loss</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Country</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Workclass  fnlwgt  Education  Education-Num  Martial_Status  \\\n",
       "0   39          5   77516          9             13               4   \n",
       "1   50          4   83311          9             13               2   \n",
       "2   38          2  215646         11              9               0   \n",
       "3   53          2  234721          1              7               2   \n",
       "4   28          2  338409          9             13               2   \n",
       "\n",
       "   Occupation  Relationship  Race  Sex  Capital_Gain  Capital_Loss  Hour  \\\n",
       "0           0             1     4    1          2174             0    40   \n",
       "1           3             0     4    1             0             0    13   \n",
       "2           5             1     4    1             0             0    40   \n",
       "3           5             0     2    1             0             0    40   \n",
       "4           9             5     2    0             0             0    40   \n",
       "\n",
       "   Country  Target  \n",
       "0       38       1  \n",
       "1       38       1  \n",
       "2       38       1  \n",
       "3       38       1  \n",
       "4        4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# Encode the categorical features as numbers\n",
    "def number_encode_features(df):\n",
    "    result = df.copy()\n",
    "    encoders = {}\n",
    "#     df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "    for column in result.columns:\n",
    "        if result.dtypes[column] == np.object:\n",
    "            encoders[column] = preprocessing.LabelEncoder()\n",
    "            result[column] = encoders[column].fit_transform(result[column])\n",
    "    return result, encoders\n",
    "    \n",
    "# Calculate the correlation and plot it\n",
    "encoded_data, _ = number_encode_features(data)\n",
    "asf = encoded_data\n",
    "asf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshil/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(encoded_data[encoded_data.columns - [\"Target\"]], encoded_data[\"Target\"], train_size=0.70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train[0:100]\n",
    "X_test = X_test[0:10]\n",
    "y_train = y_train[0:100]\n",
    "y_test = y_test[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear')\n",
    "# type(train)\n",
    "\n",
    "\n",
    "svc.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77000000000000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28368    1\n",
      "14599    0\n",
      "18824    1\n",
      "28358    1\n",
      "26436    1\n",
      "16497    1\n",
      "7720     1\n",
      "30190    1\n",
      "30960    0\n",
      "6193     1\n",
      "Name: Target, dtype: int64\n",
      "[0 0 1 0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "predicted= svc.predict(X_test)\n",
    "print y_test\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 5],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "skm.confusion_matrix(predicted, y_test)\n",
    "skm.scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
