{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "import sklearn as skl\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.cross_validation as cross_validation\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.tree as tree\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.stats import trim_mean, kurtosis\n",
    "from scipy.stats.mstats import mode, gmean, hmean\n",
    "import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/harshil/BDAP/Python Code/adultdata.csv\", names = [\"Age\", \"Workclass\", \"fnlwgt\", \n",
    "        \"Education\", \"Education-Num\", \"Martial_Status\",\"Occupation\", \"Relationship\", \"Race\", \"Sex\",\n",
    "        \"Capital_Gain\", \"Capital_Loss\",\"Hour\", \"Country\", \"Target\"],\n",
    "        sep=r'\\s*,\\s*',engine='python',na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------5 number summary----------------------\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------MEASURES OF VARIABILITY---------------\n",
    "print data.std()\n",
    "print data.quantile([.25,.5,.75])\n",
    "print data.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-----------QQ PLOTS------------------------------\n",
    "import scipy.stats as stats\n",
    "import pylab\n",
    "stats.probplot(data[\"Age\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(321)\n",
    "stats.probplot(data[\"fnlwgt\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(322)\n",
    "stats.probplot(data[\"Education-Num\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(323)\n",
    "stats.probplot(data[\"Capital_Gain\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(324)\n",
    "stats.probplot(data[\"Capital_Loss\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(325)\n",
    "stats.probplot(data[\"Hour\"], dist=\"norm\", plot=pylab)\n",
    "pylab.subplot(326)\n",
    "\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------BOX PLOT-----------------------------\n",
    "# import plotly.graph_objs as go\n",
    "import math as m \n",
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 3\n",
    "rows = m.ceil(float(data.shape[1]) / cols)\n",
    "j = 0 \n",
    "for i, column in enumerate(data.columns):\n",
    "    if data.dtypes[column] != np.object:\n",
    "        j += 1\n",
    "        ax = fig.add_subplot(2, cols, j)\n",
    "        ax.set_title(column)\n",
    "        plt.boxplot(data[column])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#------------HISTOGRAM-----------------------------\n",
    "# Analyse Data\n",
    "\n",
    "import math as m \n",
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 5\n",
    "rows = m.ceil(float(data.shape[1]) / cols)\n",
    "for i, column in enumerate(data.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    if data.dtypes[column] == np.object:\n",
    "        data[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "    else:\n",
    "        data[column].hist(axes=ax)\n",
    "        plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(data[\"Country\"].value_counts() / data.shape[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBSERVATIONS\n",
    "1. Most of the data is concentrated around US\n",
    "\n",
    "### Need to   Correlation\n",
    "\n",
    "1. Need to convert categorical variable into numerical variables. Using Label Encoder \n",
    "2. Remove correlated variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Encode the categorical features as numbers\n",
    "def number_encode_features(df):\n",
    "    result = df.copy()\n",
    "    encoders = {}\n",
    "#     df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "    for column in result.columns:\n",
    "        if result.dtypes[column] == np.object:\n",
    "            encoders[column] = preprocessing.LabelEncoder()\n",
    "            result[column] = encoders[column].fit_transform(result[column])\n",
    "    return result, encoders\n",
    "    \n",
    "\n",
    "# Calculate the correlation and plot it\n",
    "encoded_data, _ = number_encode_features(data)\n",
    "sns.heatmap(encoded_data.corr(), square=True)\n",
    "plt.show()\n",
    "# Label encoder function in scikit-learn package is used  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[[\"Education\", \"Education-Num\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We Remove Education column as Education and Education-Num are highly correlated.\n",
    "- Now to model the data, we encode the categorical variable and create histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_data, encoders = number_encode_features(data)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 5\n",
    "rows = m.ceil(float(encoded_data.shape[1]) / cols)\n",
    "for i, column in enumerate(encoded_data.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    encoded_data[column].hist(axes=ax)\n",
    "    plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before modelling, we divide the data into train and test sets. We scale all the data with mean 0 and variance 1 using StandardScalar in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(encoded_data[encoded_data.columns - [\"Target\"]], encoded_data[\"Target\"], train_size=0.70)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train.astype('float64')), columns=X_train.columns)\n",
    "X_test = scaler.transform(X_test.astype(\"float64\"))\n",
    "# ?X_train.astype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls = linear_model.LogisticRegression()\n",
    "\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=encoders[\"Target\"].classes_, yticklabels=encoders[\"Target\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "print \"F1 score: %f\" % skl.metrics.f1_score(y_test, y_pred)\n",
    "coefs = pd.Series(cls.coef_[0], index=X_train.columns)\n",
    "coefs.sort()\n",
    "plt.subplot(2,1,2)\n",
    "coefs.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Label encoding, the marital status values are ranging from 0 to 6 and the order is important. In practice there\n",
    "is no particular order in that feature. We can fix the issue using binary features by inrtoducing dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_data = pd.get_dummies(data)\n",
    "# Let's fix the Target as it will be converted to dummy vars too\n",
    "binary_data[\"Target\"] = binary_data[\"Target_>50K\"]\n",
    "del binary_data[\"Target_<=50K\"]\n",
    "del binary_data[\"Target_>50K\"]\n",
    "plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(binary_data.corr(), square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(binary_data[binary_data.columns - [\"Target\"]], binary_data[\"Target\"], train_size=0.70)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.658531\n"
     ]
    }
   ],
   "source": [
    "cls = linear_model.LogisticRegression()\n",
    "\n",
    "cls.fit(X_train, y_train)\n",
    "y_pred = cls.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2,1,1)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=encoders[\"Target\"].classes_, yticklabels=encoders[\"Target\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")\n",
    "print \"F1 score: %f\" % skl.metrics.f1_score(y_test, y_pred)\n",
    "coefs = pd.Series(cls.coef_[0], index=X_train.columns)\n",
    "coefs.sort_values(inplace=True)\n",
    "ax = plt.subplot(2,1,2)\n",
    "coefs.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries: dataframe manipulation, machine learning, os tools\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    " # Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# change working directory to where the dataset is\n",
    "# os.chdir(\"C:/Users/JD87417/Desktop/python work/Coursera\")\n",
    "\n",
    "# Load the dataset (http://archive.ics.uci.edu/ml/datasets/Adult)\n",
    "AH_data = pd.read_csv(\"/home/harshil/BDAP/Python Code/adultdata.csv\")\n",
    "data_clean = AH_data.dropna()\n",
    "\n",
    "\n",
    "# encode categorical features\n",
    "# done in R (C:\\Users\\JD87417\\Desktop\\python work\\Coursera\\python_adult2_clean.R)\n",
    "\n",
    "# summary statistics including counts, mean, stdev, quartiles\n",
    "data_clean.head(n=5)\n",
    "data_clean.dtypes # data types of each variable\n",
    "data_clean.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split into training and testing sets\n",
    "# Specifying predictor x variables\n",
    "predictors = data_clean[[\"age\", \"workclassLocal-gov\", \"workclassPrivate\",\n",
    "\"workclassSelf-emp-inc\", \"workclassSelf-emp-not-inc\", \"workclassState-gov\",\n",
    "\"workclassWithout-pay\", \"fnlwgt\", \"education11th\", \"education12th\",\n",
    "\"education1st-4th\", \"education5th-6th\", \"education7th-8th\", \"education9th\",\n",
    "\"educationAssoc-acdm\", \"educationAssoc-voc\", \"educationBachelors\",\n",
    "\"educationDoctorate\", \"educationHS-grad\", \"educationMasters\",\n",
    "\"educationPreschool\", \"educationProf-school\", \"educationSome-college\",\n",
    "\"education_num\", \"martial_statusMarried-AF-spouse\", \"martial_statusMarried-civ-spouse\",\n",
    "\"martial_statusMarried-spouse-absent\", \"martial_statusNever-married\",\n",
    "\"martial_statusSeparated\", \"martial_statusWidowed\", \"occupationArmed-Forces\",\n",
    "\"occupationCraft-repair\", \"occupationExec-managerial\", \"occupationFarming-fishing\",\n",
    "\"occupationHandlers-cleaners\", \"occupationMachine-op-inspct\",\n",
    "\"occupationOther-service\", \"occupationPriv-house-serv\", \"occupationProf-specialty\",\n",
    "\"occupationProtective-serv\", \"occupationSales\", \"occupationTech-support\",\n",
    "\"occupationTransport-moving\", \"relationshipNot-in-family\", \"relationshipOther-relative\",\n",
    "\"relationshipOwn-child\", \"relationshipUnmarried\", \"relationshipWife\",\n",
    "\"raceAsian-Pac-Islander\", \"raceBlack\", \"raceOther\", \"raceWhite\",\n",
    "\"sexMale\", \"capital_gain\", \"capital_loss\", \"hours_per_week\",\n",
    "\"native_countryCanada\", \"native_countryChina\", \"native_countryColumbia\",\n",
    "\"native_countryCuba\", \"native_countryDominican-Republic\", \"native_countryEcuador\",\n",
    "\"native_countryEl-Salvador\", \"native_countryEngland\", \"native_countryFrance\",\n",
    "\"native_countryGermany\", \"native_countryGreece\", \"native_countryGuatemala\",\n",
    "\"native_countryHaiti\", \"native_countryHoland-Netherlands\", \"native_countryHonduras\",\n",
    "\"native_countryHong\", \"native_countryHungary\", \"native_countryIndia\",\n",
    "\"native_countryIran\", \"native_countryIreland\", \"native_countryItaly\",\n",
    "\"native_countryJamaica\", \"native_countryJapan\", \"native_countryLaos\",\n",
    "\"native_countryMexico\", \"native_countryNicaragua\", \"native_countryOutlying-US(Guam-USVI-etc)\",\n",
    "\"native_countryPeru\", \"native_countryPhilippines\", \"native_countryPoland\",\n",
    "\"native_countryPortugal\", \"native_countryPuerto-Rico\", \"native_countryScotland\",\n",
    "\"native_countrySouth\", \"native_countryTaiwan\", \"native_countryThailand\",\n",
    "\"native_countryTrinadad&Tobago\", \"native_countryUnited-States\",\n",
    "\"native_countryVietnam\", \"native_countryYugoslavia\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# y repsonse variable\n",
    "targets = data_clean.income_target_50k\n",
    "\n",
    "# concurrent split of x's, y, at 40%\n",
    "pred_train, pred_test, tar_train, tar_test  = train_test_split(predictors, targets, test_size=.4)\n",
    "\n",
    "# shape/dimensions of the DataFrame\n",
    "pred_train.shape\n",
    "pred_test.shape\n",
    "tar_train.shape\n",
    "tar_test.shape\n",
    "\n",
    "# Build model on training data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators is the amount of trees to build\n",
    "classifier=RandomForestClassifier(n_estimators=25)\n",
    "# fit the RandomForest Model\n",
    "classifier=classifier.fit(pred_train,tar_train)\n",
    "# prediction scoring of the model (array of binary 0-1)\n",
    "predictions=classifier.predict(pred_test)\n",
    "# confusion matrix / missclassification matrix\n",
    "sklearn.metrics.confusion_matrix(tar_test,predictions)\n",
    "sklearn.metrics.accuracy_score(tar_test, predictions)\n",
    "\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(pred_train,tar_train)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)\n",
    "\n",
    "print(max(model.feature_importances_))\n",
    "max_val = np.where(model.feature_importances_ == max(model.feature_importances_))\n",
    "\n",
    "min_val = np.where(model.feature_importances_ == min(model.feature_importances_))\n",
    "\n",
    "print(max_val, min_val)\n",
    "\n",
    "\"\"\"\n",
    "Running a different number of trees and see the effect\n",
    " of that on the accuracy of the prediction\n",
    "\"\"\"\n",
    "\n",
    "trees=range(25)\n",
    "accuracy=np.zeros(25)\n",
    "\n",
    "for idx in range(len(trees)):\n",
    "   classifier=RandomForestClassifier(n_estimators=idx + 1)\n",
    "   classifier=classifier.fit(pred_train,tar_train)\n",
    "   predictions=classifier.predict(pred_test)\n",
    "   accuracy[idx]=sklearn.metrics.accuracy_score(tar_test, predictions)\n",
    "\n",
    "plt.cla()\n",
    "plt.plot(trees, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
